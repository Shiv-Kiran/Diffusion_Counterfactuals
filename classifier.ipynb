{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/neha-mac/Documents/Diff-CF/Diff-SCM-main\n"
     ]
    }
   ],
   "source": [
    "cd Diff-SCM-main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist\n",
      "Logging to /Users/neha-mac/Documents/Diff-CF/experiment_data/exp_02_MNIST/classifier_train_class\n",
      "creating model and diffusion...\n",
      "EncoderUNetModel(\n",
      "  (time_embed): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=128, bias=True)\n",
      "    (1): SiLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (input_blocks): ModuleList(\n",
      "    (0): TimestepEmbedSequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
      "          (1): Identity()\n",
      "          (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
      "          (1): Identity()\n",
      "          (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Downsample(\n",
      "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        )\n",
      "        (x_upd): Downsample(\n",
      "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        )\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
      "          (1): Identity()\n",
      "          (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
      "          (1): Identity()\n",
      "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Downsample(\n",
      "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        )\n",
      "        (x_upd): Downsample(\n",
      "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        )\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "      )\n",
      "    )\n",
      "    (5): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
      "          (1): Identity()\n",
      "          (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=128, out_features=256, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (6): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "          (1): Identity()\n",
      "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Downsample(\n",
      "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        )\n",
      "        (x_upd): Downsample(\n",
      "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "        )\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=128, out_features=256, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "      )\n",
      "    )\n",
      "    (7): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "          (1): Identity()\n",
      "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=128, out_features=256, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0, inplace=False)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (middle_block): TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "        (1): Identity()\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=128, out_features=256, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Identity()\n",
      "    )\n",
      "    (1): AttentionBlock(\n",
      "      (norm): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "      (qkv): Conv1d(128, 384, kernel_size=(1,), stride=(1,))\n",
      "      (attention): QKVAttention()\n",
      "      (encoder_kv): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
      "      (proj_out): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "        (1): Identity()\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=128, out_features=256, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Identity()\n",
      "    )\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): AttentionPool2d(\n",
      "      (qkv_proj): Conv1d(128, 384, kernel_size=(1,), stride=(1,))\n",
      "      (c_proj): Conv1d(128, 10, kernel_size=(1,), stride=(1,))\n",
      "      (attention): QKVAttention()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "##########$$$$$$$$$44\n",
      "encoderrrrrrrrr\n",
      "creating data loader...\n",
      "root-dir /Users/neha-mac/Documents/Diff-CF/Diff-SCM-main/remote/rds/groups/idcom_imaging/data/Brain/BRATS/MNIST\n",
      "root-dir /Users/neha-mac/Documents/Diff-CF/Diff-SCM-main/remote/rds/groups/idcom_imaging/data/Brain/BRATS/MNIST\n",
      "training...\n",
      "creating optimizer...\n",
      "training classifier model...\n",
      "-------------------------\n",
      "| grad_norm  | 3        |\n",
      "| param_norm | 56.4     |\n",
      "| samples    | 256      |\n",
      "| step       | 0        |\n",
      "| train_loss | 2.31     |\n",
      "| val_loss   | 2.3      |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 2.92     |\n",
      "| param_norm | 56.4     |\n",
      "| samples    | 2.59e+04 |\n",
      "| step       | 100      |\n",
      "| train_loss | 2.03     |\n",
      "| val_loss   | 1.86     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 6        |\n",
      "| param_norm | 56.5     |\n",
      "| samples    | 5.15e+04 |\n",
      "| step       | 200      |\n",
      "| train_loss | 1.42     |\n",
      "| val_loss   | 1.39     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 5.07     |\n",
      "| param_norm | 56.6     |\n",
      "| samples    | 7.71e+04 |\n",
      "| step       | 300      |\n",
      "| train_loss | 1.3      |\n",
      "| val_loss   | 1.21     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 4.42     |\n",
      "| param_norm | 56.6     |\n",
      "| samples    | 1.03e+05 |\n",
      "| step       | 400      |\n",
      "| train_loss | 1.29     |\n",
      "| val_loss   | 1.25     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 4.06     |\n",
      "| param_norm | 56.7     |\n",
      "| samples    | 1.28e+05 |\n",
      "| step       | 500      |\n",
      "| train_loss | 1.26     |\n",
      "| val_loss   | 1.23     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 4.06     |\n",
      "| param_norm | 56.7     |\n",
      "| samples    | 1.54e+05 |\n",
      "| step       | 600      |\n",
      "| train_loss | 1.23     |\n",
      "| val_loss   | 1.21     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 3.76     |\n",
      "| param_norm | 56.7     |\n",
      "| samples    | 1.79e+05 |\n",
      "| step       | 700      |\n",
      "| train_loss | 1.21     |\n",
      "| val_loss   | 1.19     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 3.69     |\n",
      "| param_norm | 56.7     |\n",
      "| samples    | 2.05e+05 |\n",
      "| step       | 800      |\n",
      "| train_loss | 1.22     |\n",
      "| val_loss   | 1.2      |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 3.5      |\n",
      "| param_norm | 56.8     |\n",
      "| samples    | 2.31e+05 |\n",
      "| step       | 900      |\n",
      "| train_loss | 1.21     |\n",
      "| val_loss   | 1.37     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 3.51     |\n",
      "| param_norm | 56.8     |\n",
      "| samples    | 2.56e+05 |\n",
      "| step       | 1e+03    |\n",
      "| train_loss | 1.21     |\n",
      "| val_loss   | 1.3      |\n",
      "-------------------------\n",
      "saving model...\n",
      "-------------------------\n",
      "| grad_norm  | 3.3      |\n",
      "| param_norm | 56.8     |\n",
      "| samples    | 2.82e+05 |\n",
      "| step       | 1.1e+03  |\n",
      "| train_loss | 1.2      |\n",
      "| val_loss   | 1.16     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 3.25     |\n",
      "| param_norm | 56.8     |\n",
      "| samples    | 3.07e+05 |\n",
      "| step       | 1.2e+03  |\n",
      "| train_loss | 1.2      |\n",
      "| val_loss   | 1.25     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 3.12     |\n",
      "| param_norm | 56.8     |\n",
      "| samples    | 3.33e+05 |\n",
      "| step       | 1.3e+03  |\n",
      "| train_loss | 1.2      |\n",
      "| val_loss   | 1.17     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 3        |\n",
      "| param_norm | 56.9     |\n",
      "| samples    | 3.59e+05 |\n",
      "| step       | 1.4e+03  |\n",
      "| train_loss | 1.21     |\n",
      "| val_loss   | 1.12     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 3        |\n",
      "| param_norm | 56.9     |\n",
      "| samples    | 3.84e+05 |\n",
      "| step       | 1.5e+03  |\n",
      "| train_loss | 1.21     |\n",
      "| val_loss   | 1.11     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 2.87     |\n",
      "| param_norm | 56.9     |\n",
      "| samples    | 4.1e+05  |\n",
      "| step       | 1.6e+03  |\n",
      "| train_loss | 1.18     |\n",
      "| val_loss   | 1.35     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 2.91     |\n",
      "| param_norm | 56.9     |\n",
      "| samples    | 4.35e+05 |\n",
      "| step       | 1.7e+03  |\n",
      "| train_loss | 1.18     |\n",
      "| val_loss   | 1.21     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 2.73     |\n",
      "| param_norm | 56.9     |\n",
      "| samples    | 4.61e+05 |\n",
      "| step       | 1.8e+03  |\n",
      "| train_loss | 1.21     |\n",
      "| val_loss   | 1.12     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 2.7      |\n",
      "| param_norm | 57       |\n",
      "| samples    | 4.87e+05 |\n",
      "| step       | 1.9e+03  |\n",
      "| train_loss | 1.18     |\n",
      "| val_loss   | 1.32     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 2.8      |\n",
      "| param_norm | 57       |\n",
      "| samples    | 5.12e+05 |\n",
      "| step       | 2e+03    |\n",
      "| train_loss | 1.21     |\n",
      "| val_loss   | 1.13     |\n",
      "-------------------------\n",
      "saving model...\n",
      "-------------------------\n",
      "| grad_norm  | 2.74     |\n",
      "| param_norm | 57       |\n",
      "| samples    | 5.38e+05 |\n",
      "| step       | 2.1e+03  |\n",
      "| train_loss | 1.17     |\n",
      "| val_loss   | 1.18     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 2.73     |\n",
      "| param_norm | 57       |\n",
      "| samples    | 5.63e+05 |\n",
      "| step       | 2.2e+03  |\n",
      "| train_loss | 1.18     |\n",
      "| val_loss   | 1.16     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 2.57     |\n",
      "| param_norm | 57       |\n",
      "| samples    | 5.89e+05 |\n",
      "| step       | 2.3e+03  |\n",
      "| train_loss | 1.17     |\n",
      "| val_loss   | 1.14     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 2.64     |\n",
      "| param_norm | 57       |\n",
      "| samples    | 6.15e+05 |\n",
      "| step       | 2.4e+03  |\n",
      "| train_loss | 1.18     |\n",
      "| val_loss   | 1.15     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 2.52     |\n",
      "| param_norm | 57.1     |\n",
      "| samples    | 6.4e+05  |\n",
      "| step       | 2.5e+03  |\n",
      "| train_loss | 1.17     |\n",
      "| val_loss   | 1.22     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 2.55     |\n",
      "| param_norm | 57.1     |\n",
      "| samples    | 6.66e+05 |\n",
      "| step       | 2.6e+03  |\n",
      "| train_loss | 1.15     |\n",
      "| val_loss   | 1.09     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 2.53     |\n",
      "| param_norm | 57.1     |\n",
      "| samples    | 6.91e+05 |\n",
      "| step       | 2.7e+03  |\n",
      "| train_loss | 1.17     |\n",
      "| val_loss   | 1.1      |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 2.52     |\n",
      "| param_norm | 57.1     |\n",
      "| samples    | 7.17e+05 |\n",
      "| step       | 2.8e+03  |\n",
      "| train_loss | 1.16     |\n",
      "| val_loss   | 1.32     |\n",
      "-------------------------\n",
      "-------------------------\n",
      "| grad_norm  | 2.47     |\n",
      "| param_norm | 57.1     |\n",
      "| samples    | 7.43e+05 |\n",
      "| step       | 2.9e+03  |\n",
      "| train_loss | 1.15     |\n",
      "| val_loss   | 1.09     |\n",
      "-------------------------\n",
      "saving model...\n"
     ]
    }
   ],
   "source": [
    "!python /Users/neha-mac/Documents/Diff-CF/Diff-SCM-main/diff_scm/training/anticausal_classifier_train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
